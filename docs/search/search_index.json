{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Axcent - AI Agent Framework The easiest way to build AI agents in Python. Axcent is a lightweight framework designed to let you build powerful AI agents with tool calling, context caching, and multi-backend support in just a few lines of code. Installation pip install axcent Quick Start from axcent import Agent agent = Agent(system_prompt=\"You are a helpful assistant.\") response = agent.ask(\"Hello!\") print(response)","title":"Home"},{"location":"#axcent-ai-agent-framework","text":"The easiest way to build AI agents in Python. Axcent is a lightweight framework designed to let you build powerful AI agents with tool calling, context caching, and multi-backend support in just a few lines of code.","title":"Axcent - AI Agent Framework"},{"location":"#installation","text":"pip install axcent","title":"Installation"},{"location":"#quick-start","text":"from axcent import Agent agent = Agent(system_prompt=\"You are a helpful assistant.\") response = agent.ask(\"Hello!\") print(response)","title":"Quick Start"},{"location":"api/","text":"API Reference axcent.core.Agent The main class for interacting with the LLM. __init__ def __init__(self, system_prompt: str = \"...\", backend: LLMBackend = None, model: str = \"gpt-4o-mini\") system_prompt : The initial instruction for the agent. backend : An instance of LLMBackend (default: OpenAIBackend ). model : The model name string (used if backend is default). ask def ask(self, query: str) -> str Sends a user query to the agent. Handles the conversation loop including tool execution. tool @agent.tool def my_function(): ... Decorator to register a function as a tool. get_total_usage def get_total_usage(self) -> Dict[str, int] Returns a dictionary containing token usage statistics (prompt, completion, total, cached). axcent.llm OpenAIBackend Standard backend for OpenAI-compatible APIs. GeminiBackend Backend for Google's Gemini models using google-genai SDK. MockBackend Backend for testing without API calls.","title":"API Reference"},{"location":"api/#api-reference","text":"","title":"API Reference"},{"location":"api/#axcentcoreagent","text":"The main class for interacting with the LLM.","title":"axcent.core.Agent"},{"location":"api/#__init__","text":"def __init__(self, system_prompt: str = \"...\", backend: LLMBackend = None, model: str = \"gpt-4o-mini\") system_prompt : The initial instruction for the agent. backend : An instance of LLMBackend (default: OpenAIBackend ). model : The model name string (used if backend is default).","title":"__init__"},{"location":"api/#ask","text":"def ask(self, query: str) -> str Sends a user query to the agent. Handles the conversation loop including tool execution.","title":"ask"},{"location":"api/#tool","text":"@agent.tool def my_function(): ... Decorator to register a function as a tool.","title":"tool"},{"location":"api/#get_total_usage","text":"def get_total_usage(self) -> Dict[str, int] Returns a dictionary containing token usage statistics (prompt, completion, total, cached).","title":"get_total_usage"},{"location":"api/#axcentllm","text":"","title":"axcent.llm"},{"location":"api/#openaibackend","text":"Standard backend for OpenAI-compatible APIs.","title":"OpenAIBackend"},{"location":"api/#geminibackend","text":"Backend for Google's Gemini models using google-genai SDK.","title":"GeminiBackend"},{"location":"api/#mockbackend","text":"Backend for testing without API calls.","title":"MockBackend"},{"location":"getting-started/","text":"Getting Started Basic Usage The core of Axcent is the Agent class. import os from axcent import Agent # 1. Set your API Key os.environ[\"OPENAI_API_KEY\"] = \"sk-...\" # 2. Initialize Agent agent = Agent(system_prompt=\"You are a helpful assistant.\") # 3. Ask a question response = agent.ask(\"What is the capital of France?\") print(response) Using Tools Axcent makes it incredibly easy to give your agent tools. Just define a python function and use the @agent.tool decorator. @agent.tool def get_weather(city: str) -> str: \"\"\"Get the current weather for a city.\"\"\" # In a real app, you'd call an API here return f\"The weather in {city} is sunny!\" response = agent.ask(\"What's the weather in Tokyo?\") print(response) The Docstring and Type Hints are automatically converted to the JSON schema required by the LLM. Multi-Backend Support Axcent supports multiple LLM providers. Google Gemini from axcent import Agent, GeminiBackend import os os.environ[\"GEMINI_API_KEY\"] = \"AIza...\" # Use Gemini Backend (V2) backend = GeminiBackend(model=\"gemini-2.0-flash-exp\") agent = Agent(system_prompt=\"You are a helper.\", backend=backend) OpenRouter import os from axcent import Agent os.environ[\"OPENAI_API_KEY\"] = \"sk-or-...\" os.environ[\"OPENAI_BASE_URL\"] = \"https://openrouter.ai/api/v1\" agent = Agent(system_prompt=\"You are a helper.\")","title":"Getting Started"},{"location":"getting-started/#getting-started","text":"","title":"Getting Started"},{"location":"getting-started/#basic-usage","text":"The core of Axcent is the Agent class. import os from axcent import Agent # 1. Set your API Key os.environ[\"OPENAI_API_KEY\"] = \"sk-...\" # 2. Initialize Agent agent = Agent(system_prompt=\"You are a helpful assistant.\") # 3. Ask a question response = agent.ask(\"What is the capital of France?\") print(response)","title":"Basic Usage"},{"location":"getting-started/#using-tools","text":"Axcent makes it incredibly easy to give your agent tools. Just define a python function and use the @agent.tool decorator. @agent.tool def get_weather(city: str) -> str: \"\"\"Get the current weather for a city.\"\"\" # In a real app, you'd call an API here return f\"The weather in {city} is sunny!\" response = agent.ask(\"What's the weather in Tokyo?\") print(response) The Docstring and Type Hints are automatically converted to the JSON schema required by the LLM.","title":"Using Tools"},{"location":"getting-started/#multi-backend-support","text":"Axcent supports multiple LLM providers.","title":"Multi-Backend Support"},{"location":"getting-started/#google-gemini","text":"from axcent import Agent, GeminiBackend import os os.environ[\"GEMINI_API_KEY\"] = \"AIza...\" # Use Gemini Backend (V2) backend = GeminiBackend(model=\"gemini-2.0-flash-exp\") agent = Agent(system_prompt=\"You are a helper.\", backend=backend)","title":"Google Gemini"},{"location":"getting-started/#openrouter","text":"import os from axcent import Agent os.environ[\"OPENAI_API_KEY\"] = \"sk-or-...\" os.environ[\"OPENAI_BASE_URL\"] = \"https://openrouter.ai/api/v1\" agent = Agent(system_prompt=\"You are a helper.\")","title":"OpenRouter"}]}